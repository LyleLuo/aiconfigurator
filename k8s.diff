*** a/src/aiconfigurator/eval/main.py
--- b/src/aiconfigurator/eval/main.py
@@
 def configure_parser(parser: argparse.ArgumentParser) -> None:
     from aiconfigurator.cli.main import configure_parser as reuse_cli_parser
     reuse_cli_parser(parser)
 
     g = parser.add_argument_group("Eval pipeline")
@@
     g.add_argument("--artifact-root", type=str, default="",
                    help="Optional base folder for eval outputs (default under save_dir).")
 
+    # --- Kubernetes args ---
+    gk = parser.add_argument_group("Kubernetes")
+    gk.add_argument("--k8s", action="store_true",
+                    help="Enable Kubernetes deployment mode.")
+    gk.add_argument("--k8s-namespace", type=str, default="ets-dynamo",
+                    help="Kubernetes namespace. Default: ets-dynamo")
+    gk.add_argument("--k8s-deploy-file", type=str, default="",
+                    help="Override path to k8s_deploy.yaml; if empty, auto-detect under backend_configs/<mode>/k8s_deploy.yaml.")
+    gk.add_argument("--k8s-engine-cm-name", type=str, default="engine-configs",
+                    help="ConfigMap name to store engine YAML(s) (Method 2).")
+    gk.add_argument("--k8s-frontend-selector", type=str,
+                    default="dynamo.nvidia.com/componentType=frontend",
+                    help="Label selector to find frontend pod for port-forward (e.g. 'app=my-frontend').")
+    gk.add_argument("--k8s-context", type=str, default="",
+                    help="kubectl context to use (optional).")
+    gk.add_argument("--k8s-delete-on-stop", action="store_true",
+                    help="Delete the deployed graph on stop.")
+    gk.add_argument("--k8s-pf-kind", choices=["pod", "svc"], default="pod",
+                    help="Resource kind to port-forward: pod or svc. Default: pod")
+    gk.add_argument("--k8s-pf-name", type=str, default="",
+                    help="Explicit resource name to port-forward; if empty, first Ready frontend pod is used.")
+    gk.add_argument("--k8s-wait-timeout-s", type=int, default=900,
+                    help="Max seconds to wait for pods to be Ready in k8s mode. Default: 900")
@@
     cfg = EvalConfig(
         mode=args.mode,
         service_dir=args.service_dir,
         start_script=args.start_script,
         port=port,
         health_timeout_s=args.health_timeout_s,
         coldstart_wait_s=args.coldstart_wait_s,
         no_generate=args.no_generate,
         gpu_monitor=bool(getattr(args, "gpu_monitor", False)),
         nvml_interval_s=args.nvml_interval_s,
         bench_concurrency=list(args.benchmark_concurrency or []),
         runs=args.runs,
         artifact_root=args.artifact_root or "",
         cli_args=args,
+        # k8s
+        k8s_enabled=bool(getattr(args, "k8s", False)),
+        k8s_namespace=args.k8s_namespace,
+        k8s_deploy_file=args.k8s_deploy_file,
+        k8s_engine_cm_name=args.k8s_engine_cm_name,
+        k8s_frontend_selector=args.k8s_frontend_selector,
+        k8s_context=(args.k8s_context or ""),
+        k8s_delete_on_stop=bool(getattr(args, "k8s_delete_on_stop", False)),
+        k8s_pf_kind=args.k8s_pf_kind,
+        k8s_pf_name=args.k8s_pf_name or "",
+        k8s_wait_timeout_s=args.k8s_wait_timeout_s,
     )
